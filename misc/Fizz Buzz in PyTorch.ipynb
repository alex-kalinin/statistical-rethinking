{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by https://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will represent input numbers as bits. We'll  support 12-bit numbers, in the range [0,4095]. We will train on number in [101, 4095]. The final test will be, per problem definition, in [1, 100]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BITS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(i, num_bits):\n",
    "    digits = np.array([i >> d & 1 for d in range(num_bits)])\n",
    "    # Reverses the array to have the bits in the usual order.\n",
    "    return digits[::-1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: convert 4 to the binary representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_binary(4, BITS)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels will be encoded as indices of the array, i.e. 0, 1, 2, and 3. The labels mark expected answers, e.g.:\n",
    "\n",
    "* 333 is \"fizz\" -> 0\n",
    "* 115 is \"buzz\" -> 1\n",
    "* 225 is \"fizbuzz\" -> 2, etc. \n",
    "\n",
    "We won't label numbers < 101 because those will be used during the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_text = [\n",
    "    'fizz', \n",
    "    'buzz', \n",
    "    'fizzbuzz',\n",
    "    ''\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(i):\n",
    "    if   i % 15 == 0: return 2\n",
    "    elif i % 5  == 0: return 1\n",
    "    elif i % 3  == 0: return 0\n",
    "    else:             return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label(333), get_label(115), get_label(225)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the training set. It's two arrays. The first array contains integers, in the bit format, the second array has the corresponding labels, in the integer format (0, 1, 2, 3) as shown above. I.e.:\n",
    "```\n",
    "1. train_x: [101, 102, 103, ..., 4095]\n",
    "2. train_y: [  3,   0,   3, ...,    2]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array([to_binary(i, BITS) for i in range(101, 2**BITS)])\n",
    "train_y = np.array([get_label(i) for i in range(101, 2**BITS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'fizz', '']\n"
     ]
    }
   ],
   "source": [
    "print([label_text[i] for i in train_y[:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network is a *classifier*, i.e. it puts every input into one of the four classses: [0, 1, 2, 3] which correspond to the string values ['fizz', 'buzz', 'fizzbuzz','']. \n",
    "\n",
    "For classifiers we use negative log-loss function. Training the network means minimizing the value of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy function calculates how many numbers we classified correctly from our test range, [1-100]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,  loss):\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    for i in range(1, 100):\n",
    "        expect = get_label(i)\n",
    "        test_x.append(to_binary(i, BITS))\n",
    "        test_y.append(expect)\n",
    "    x = torch.from_numpy(np.array(test_x)).float()\n",
    "    y = torch.from_numpy(np.array(test_y))\n",
    "    pred_y = model(x)\n",
    "    pred = torch.argmax(pred_y, dim=1)\n",
    "    acc = (y == pred).sum().float() / x.shape[0]\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(BITS, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, len(label_text)),\n",
    "        nn.LogSoftmax(dim=-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=5e-3, \n",
    "    momentum=0.9, \n",
    "    nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training loop**. We use stochastic gradient descent. This mean we pick a small number of training samples, e.g. 32, and performance one iteration of training on this sample. Then we pick another 32 samples, and so on. Training on smaller samples is much faster than on the data dataset every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 Loss: 1.0706539154052734 test accuracy: 0.5353535413742065\n",
      "101 0 Loss: 0.737541913986206 test accuracy: 0.6464646458625793\n",
      "201 0 Loss: 0.14468005299568176 test accuracy: 1.0\n",
      "301 0 Loss: 0.07151934504508972 test accuracy: 0.9898989796638489\n",
      "401 0 Loss: 0.0478881299495697 test accuracy: 0.9898989796638489\n",
      "499 124 Loss: 0.15687410533428192 test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn.utils \n",
    "\n",
    "train_x, train_y = sklearn.utils.shuffle(train_x, train_y)\n",
    "\n",
    "train_x_t = torch.from_numpy(train_x).float()\n",
    "train_y_t = torch.from_numpy(train_y)\n",
    "\n",
    "print_every=100\n",
    "batch_size = 32\n",
    "test_pred = None\n",
    "\n",
    "for i in range(500):\n",
    "    batches = int(train_x.shape[0] / batch_size + 1)\n",
    "    printed = False\n",
    "    for b in range(batches):\n",
    "        start = b * batch_size\n",
    "        end = (b + 1) * batch_size\n",
    "        bt = train_x_t[start:end]\n",
    "        by = train_y_t[start:end]\n",
    "        y_pred = model(bt)\n",
    "        loss_val = loss(y_pred, by)\n",
    "        model.zero_grad()\n",
    "        loss_val.backward()\n",
    "        opt.step()\n",
    "        if i % print_every == 1 and not printed:\n",
    "            print(i, b, \"Loss:\", loss_val.item(), \"test accuracy:\", accuracy(model, loss))\n",
    "            printed = True\n",
    "print(i, b, \"Loss:\", loss_val.item(), \"test accuracy:\", accuracy(model, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network achieves 100% accuracy on the test set, i.e. in the range 1-100. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict function:\n",
    "\n",
    "1. Convert the number into the bit format.\n",
    "1. Apply the train neural network to obtain the predicted 'class', i.e. 0, 1, 2, or 3.\n",
    "1. Look up the text label for the returned class and print it along with original number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(num):\n",
    "    enc = to_binary(num, BITS)\n",
    "    enc = torch.from_numpy(enc).float()\n",
    "    pred = model(enc)\n",
    "    pred = torch.exp(pred)\n",
    "    index = torch.argmax(pred).item()\n",
    "    return (num, label_text[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75, 'fizzbuzz'), (10, 'buzz'), (3, 'fizz'), (21, 'fizz'), (7, ''))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(75), predict(10), predict(3), predict(21), predict(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
