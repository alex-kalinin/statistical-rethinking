{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by https://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/.\n",
    "\n",
    "### Problem Definition\n",
    "\n",
    "For numbers betwen 1 and 100:\n",
    "   * if the number is the multiple of 3, print \"fizz\",\n",
    "   * if the number is the multiple of 5, print \"buzz\",\n",
    "   * if the number is the multiple of both 3 and 5, print \"fizzbuzz\",\n",
    "   * otherwise, print the number itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will represent input numbers as bits. We'll  support 12-bit numbers, in the range of [0,4095]. We'll train on numbers in the range of [101, 4095]. The final test will be, per problem definition, in [1, 100]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BITS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(i, num_bits):\n",
    "    digits = np.array([i >> d & 1 for d in range(num_bits)])\n",
    "    # Reverses the array to have the bits in the usual order.\n",
    "    return digits[::-1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: convert 4 to the binary representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_binary(4, BITS)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels will be encoded as indices of the array, i.e. 0, 1, 2, and 3. The labels mark expected answers, e.g.:\n",
    "\n",
    "* 333 is \"fizz\" -> 0\n",
    "* 115 is \"buzz\" -> 1\n",
    "* 225 is \"fizbuzz\" -> 2, etc. \n",
    "\n",
    "We won't label numbers < 101 because those will be used during the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_text = [\n",
    "    'fizz', \n",
    "    'buzz', \n",
    "    'fizzbuzz',\n",
    "    ''\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(i):\n",
    "    if   i % 15 == 0: return 2\n",
    "    elif i % 5  == 0: return 1\n",
    "    elif i % 3  == 0: return 0\n",
    "    else:             return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label(333), get_label(115), get_label(225)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the training set. It's two arrays. The first array contains integers, in the bit format. The second array has the corresponding labels, in the integer format (0, 1, 2, 3) as shown above. I.e.:\n",
    "```\n",
    "1. train_x: [101, 102, 103, ..., 4095]\n",
    "2. train_y: [  3,   0,   3, ...,    2]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array([to_binary(i, BITS) for i in range(101, 2**BITS)])\n",
    "train_y = np.array([get_label(i) for i in range(101, 2**BITS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'fizz', '']\n"
     ]
    }
   ],
   "source": [
    "print([label_text[i] for i in train_y[:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network is a *classifier*, i.e. it puts every input into one of the four classses: [0, 1, 2, 3] which correspond to the string values ['fizz', 'buzz', 'fizzbuzz','']. \n",
    "\n",
    "For classifiers we use negative log-loss function. Training the network means minimizing the value of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy function calculates how many numbers we classified correctly from our test range, [1-100]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,  loss):\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    for i in range(1, 100):\n",
    "        expect = get_label(i)\n",
    "        test_x.append(to_binary(i, BITS))\n",
    "        test_y.append(expect)\n",
    "    x = torch.from_numpy(np.array(test_x)).float()\n",
    "    y = torch.from_numpy(np.array(test_y))\n",
    "    pred_y = model(x)\n",
    "    pred = torch.argmax(pred_y, dim=1)\n",
    "    acc = (y == pred).sum().float() / x.shape[0]\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(BITS, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, len(label_text)),\n",
    "        nn.LogSoftmax(dim=-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=5e-3, \n",
    "    momentum=0.9, \n",
    "    nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training loop**. We use stochastic gradient descent. This mean we pick a small number of training samples, e.g. 32, and perform one iteration of training on this sample. Then, we pick another 32 samples, and so on. Training on smaller samples is much faster than on the entire dataset every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 Loss: 0.016308505088090897 test accuracy: 0.9898989796638489\n",
      "101 0 Loss: 0.011160150170326233 test accuracy: 0.9898989796638489\n",
      "201 0 Loss: 0.009250616654753685 test accuracy: 0.9898989796638489\n",
      "301 0 Loss: 0.008243781514465809 test accuracy: 0.9898989796638489\n",
      "401 0 Loss: 0.007405351847410202 test accuracy: 1.0\n",
      "499 124 Loss: 0.013771540485322475 test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn.utils \n",
    "\n",
    "train_x, train_y = sklearn.utils.shuffle(train_x, train_y)\n",
    "\n",
    "train_x_t = torch.from_numpy(train_x).float()\n",
    "train_y_t = torch.from_numpy(train_y)\n",
    "\n",
    "print_every=100\n",
    "batch_size = 32\n",
    "test_pred = None\n",
    "\n",
    "for i in range(500):\n",
    "    batches = int(train_x.shape[0] / batch_size + 1)\n",
    "    printed = False\n",
    "    for b in range(batches):\n",
    "        start = b * batch_size\n",
    "        end = (b + 1) * batch_size\n",
    "        bt = train_x_t[start:end]\n",
    "        by = train_y_t[start:end]\n",
    "        y_pred = model(bt)\n",
    "        loss_val = loss(y_pred, by)\n",
    "        model.zero_grad()\n",
    "        loss_val.backward()\n",
    "        opt.step()\n",
    "        if i % print_every == 1 and not printed:\n",
    "            print(i, b, \"Loss:\", loss_val.item(), \"test accuracy:\", accuracy(model, loss))\n",
    "            printed = True\n",
    "print(i, b, \"Loss:\", loss_val.item(), \"test accuracy:\", accuracy(model, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network achieves 100% accuracy on the test set, i.e. in the range 1-100. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict function:\n",
    "\n",
    "1. Convert the number into the bit format.\n",
    "1. Apply the train neural network to obtain the predicted 'class', i.e. 0, 1, 2, or 3.\n",
    "1. Look up the text label for the returned class and print it along with original number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(num):\n",
    "    enc = to_binary(num, BITS)\n",
    "    enc = torch.from_numpy(enc).float()\n",
    "    pred = model(enc)\n",
    "    pred = torch.exp(pred)\n",
    "    index = torch.argmax(pred).item()\n",
    "    return (num, label_text[index] if label_text[index] != '' else num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1),\n",
       " (2, 2),\n",
       " (3, 'fizz'),\n",
       " (4, 4),\n",
       " (5, 'buzz'),\n",
       " (6, 'fizz'),\n",
       " (7, 7),\n",
       " (10, 'buzz'),\n",
       " (30, 'fizzbuzz'))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(1), predict(2), predict(3), predict(4), \\\n",
    "predict(5), predict(6), predict(7), predict(10), \\\n",
    "predict(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
